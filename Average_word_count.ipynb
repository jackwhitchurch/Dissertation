{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the average word count for the column in each dataset which represents the main text of a news source e.g. \"statement\" in the LIAR dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading LIAR dataset and calculating the mean word count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.127348230176"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading both the training and testing dataset\n",
    "\n",
    "LIAR_train = pd.read_csv(\"liar_dataset/train.tsv\", sep='\\t', header=0)\n",
    "LIAR_test = pd.read_csv(\"liar_dataset/test.tsv\", sep='\\t', header=0)\n",
    "\n",
    "# Adding the column names to both dataset\n",
    "\n",
    "LIAR_train.columns =[\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job title\", \"state info\", \"party affiliation\", \"barely true counts\", \"false counts\", \"half true counts\", \"mostly true counts\", \"pants on fire counts\", \"context\"]\n",
    "LIAR_test.columns =[\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job title\", \"state info\", \"party affiliation\", \"barely true counts\", \"false counts\", \"half true counts\", \"mostly true counts\", \"pants on fire counts\", \"context\"]\n",
    "\n",
    "# Concatenating the training and test dataset\n",
    "\n",
    "LIAR_data = pd.concat([LIAR_train, LIAR_test], ignore_index=True, sort=False)\n",
    "\n",
    "# Dropping rows that do not represent exactly 'true' or 'false' information\n",
    "\n",
    "LIAR_data = LIAR_data.drop(LIAR_data.query('label == \"half-true\"').index)\n",
    "LIAR_data = LIAR_data.drop(LIAR_data.query('label == \"barely-true\"').index)\n",
    "LIAR_data = LIAR_data.drop(LIAR_data.query('label == \"mostly-true\"').index)\n",
    "\n",
    "#Calculating mean word count\n",
    "\n",
    "LIAR_data['statement_length'] = LIAR_data['statement'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "LIAR_data['statement_length'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading BuzzFeedNews dataset and calculating the mean word count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2924.1756272401435"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as et \n",
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "rows_list = []\n",
    "path = \"buzzfeed_dataset/\"\n",
    "\n",
    "# Each datapoint in the BuzzFeedNews dataset comes as a seperate xml file\n",
    "# Therefore I loop through the file directory and read each xml file, adding the contents of mainText \n",
    "# (contents of a news source) and veracity (label) to a dataframe\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.xml'):\n",
    "        fullname = os.path.join(path, filename)\n",
    "        xtree = et.parse(fullname)\n",
    "        xroot = xtree.getroot() \n",
    "        main_text = xroot.find('mainText').text\n",
    "        veracity = xroot.find('veracity').text\n",
    "        new_row = {'mainText': main_text, 'label': veracity}\n",
    "        rows_list.append(new_row)\n",
    "\n",
    "# Dropping rows that do not represent exactly 'true' or 'false' information\n",
    "\n",
    "buzzfeed_data = pd.DataFrame(rows_list)   \n",
    "buzzfeed_data = buzzfeed_data.drop(buzzfeed_data.query('label == \"mixture of true and false\"').index)\n",
    "\n",
    "# Rename rows that represent 'true' and 'false' information to \"REAL\" and \"FAKE\" since the model is trained to classify to these\n",
    "\n",
    "buzzfeed_data['label'] = buzzfeed_data['label'].replace(['mostly true','mostly false', 'no factual content'], ['REAL', 'FAKE', 'FAKE'])\n",
    "\n",
    "# Drop any rows which have an empty body\n",
    "\n",
    "buzzfeed_data.dropna(subset = ['mainText'], inplace=True)\n",
    "buzzfeed_data.dropna(subset = ['mainText'], inplace=True)\n",
    "\n",
    "#Calculating mean word count\n",
    "\n",
    "buzzfeed_data['statement_length'] = buzzfeed_data['mainText'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "buzzfeed_data['statement_length'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading McIntire dataset and calculating the mean word count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3942.6716653512235"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading dataset\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "McIntire_data = pd.read_csv(\"fake_or_real_news.csv\")\n",
    "\n",
    "#Removing unused column\n",
    "McIntire_data = McIntire_data.drop(labels = \"Unnamed: 0\", axis = 1)\n",
    "\n",
    "#Labelling remaining columns\n",
    "McIntire_data.columns=[\"title\", \"body_text\", \"label\"]\n",
    "\n",
    "#Calculating mean word count\n",
    "\n",
    "McIntire_data['statement_length'] = McIntire_data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "McIntire_data['statement_length'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
